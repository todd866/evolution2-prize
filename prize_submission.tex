\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}

\title{\textbf{Codes as Coordination: A Physical System that Generates Digital Communication Without Pre-Programming}\\[0.5em]
\large HeroX Evolution 2.0 Prize Submission}

\author{Ian Todd\\
Sydney Medical School, University of Sydney\\
\texttt{itod2305@uni.sydney.edu.au}}

\date{January 2026}

\begin{document}

\maketitle

\noindent\textbf{DATE:} January 8, 2026\\
\textbf{FULL NAME:} Ian Todd\\
\textbf{COMPANY/ORGANIZATION:} Sydney Medical School, University of Sydney\\
\textbf{WEBSITE:} \url{https://coherencedynamics.com}\\
\textbf{EMAIL:} itod2305@uni.sydney.edu.au\\
\textbf{PHONE:} +61 432 531 366

\vspace{1em}

%==============================================================================
\section{Executive Summary}
%==============================================================================

We solve the theoretical problem that has blocked progress for 70 years: \textbf{why don't abiogenesis experiments produce codes?}

The answer is \textit{effective dimensionality}. Codes require chemical dynamics spanning multiple orthogonal directions. Most experiments optimize for synthesis (convergent chemistry), which actively suppresses the divergent dynamics codes require. We prove this in simulation and provide a roadmap for physical implementation.

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Requirement} & \textbf{Our Contribution} & \textbf{Status} \\
\midrule
Encoder/Decoder/Message & Architecture defined, validated in silico & Theory \\
$\geq$32 states & Achieved in 60\% of random chemistries & Simulation \\
Digital & Emergent via substrate competition & Mechanism identified \\
No pre-programming & Coordination equilibria, not logic & Proven \\
Physical implementation & Experimentally testable predictions & Roadmap \\
\bottomrule
\end{tabular}
\end{center}

\subsection*{What We Deliver}

\textbf{1. The missing ingredient}: Effective dimensionality ($D_{\text{eff}}$) predicts code quality better than species count, reaction count, or any other parameter tested. This is why Miller-Urey, RNA World, and Lipid World experiments produce building blocks but never codes---they operate below the $D_{\text{eff}}$ threshold.

\textbf{2. A working simulation}: Mass-action kinetics (not neural networks) producing 32 distinguishable codes via substrate competition. Validated across 120 random chemistries. Open source, fully reproducible.

\textbf{3. Mechanism ablations}: We identify what's necessary (competitive normalization, inter-compartment coupling) and what's not (high cooperativity---linear competition works better).

\textbf{4. Experimental predictions}: Specific, falsifiable predictions for droplet microfluidics, BZ oscillator arrays, or protocell systems. The threshold is $D_{\text{eff}} > 1$: any diversity beyond collapsed 1D dynamics dramatically improves code quality. If codes don't emerge when $D_{\text{eff}} > 1$, the theory is wrong.

\subsection*{The Honest Framing}

This is a \textbf{theoretical solution with simulation validation}, not a physical demonstration. We cannot build the experiment without resources. But we can tell you exactly what to build and why previous attempts failed.

The \$10M prize requires physical demonstration. We submit this for consideration as a \textbf{partial solution / milestone contribution}: the theoretical breakthrough that makes physical demonstration possible.

%==============================================================================
\section{System Architecture}
%==============================================================================

\subsection{Components}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Component} & \textbf{Function} & \textbf{Implementation} \\
\midrule
Compartments & Semi-autonomous agents & 61 vesicles in hexagonal array \\
Internal dynamics & High-dimensional chemistry & 128 dimensions per compartment \\
Discretization & Emergent symbol formation & Substrate competition (30 channels) \\
Coupling & Neighbor communication & Weak boundary signal exchange \\
Spatial structure & Symmetry breaking & Center-edge, gradient differentiation \\
\bottomrule
\end{tabular}
\end{center}

\subsection{How It Works}

Each compartment contains high-dimensional nonlinear reaction dynamics (128 coupled species near the edge of instability). Output channels compete for finite substrate via \textbf{mass-action kinetics}:
\begin{itemize}
    \item \textbf{Competitive binding}: Saturation function $S^n/(K^n + S^n)$, where $n \geq 1$
    \item \textbf{Substrate competition}: Allocation $\propto \text{activity}^n / \sum(\text{activity}^n)$
    \item This is the \textbf{quasi-steady-state (QSSA)} solution to competitive binding---standard biochemistry (Michaelis-Menten, competitive inhibition), not engineered logic
\end{itemize}

Compartments are coupled through boundary signals: each vesicle's state is influenced by the average readout of its neighbors. This creates coordination pressure without global mixing.

\textbf{Environmental heterogeneity} drives differentiation: vesicles at different spatial locations experience different stimulus conditions (center vs. edge, top vs. bottom). This breaks degeneracy between input configurations. \textit{Crucially, these gradients represent non-informational geometric constraints}---e.g., a rock shading part of a tide pool, proximity to a heat source, or differential ion exposure. The complexity is not in the stimulus; it is in the system's ability to differentiate continuous gradients into discrete coordination states.

\textbf{Temporal forcing} creates genuine sequence structure: each of 4 cycles experiences different environmental conditions (modeling diurnal variation, tidal rhythms).

%==============================================================================
\section{Results}
%==============================================================================

\subsection{Performance Summary}

\begin{center}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Result} \\
\midrule
Compartments & 61 vesicles (hexagonal array) \\
Internal dimensions & 128 per compartment \\
Readout channels & 30 \\
Unique symbol sequences & 24/32 (8 collisions at symbol level) \\
Encoder reproducibility & 100\% \\
Separation ratio (between/within) & 243$\times$ \\
Bimodal fraction ($|x| > 0.5$) & 89\% \\
Decoder accuracy & 100\% (all 32 distinguishable) \\
\bottomrule
\end{tabular}
\end{center}

\noindent\textbf{Key results}:
\begin{itemize}
    \item \textbf{100\% decoder accuracy}: physics-based receiver distinguishes all 32 inputs
    \item \textbf{100\% encoder reproducibility}: same input $\to$ same output across trials
    \item \textbf{24 unique symbol sequences}: discretization loses some information, but the full 20D transmitted signal remains distinguishable
    \item \textbf{Emergent discretization}: 89\% of readout values are saturated ($|x| > 0.5$)
\end{itemize}

\subsection{Encoding Table (Full Codebook)}

Complete 4-symbol character sequences for all 32 configurations:

\begin{center}
\scriptsize
\begin{tabular}{ccccccc}
\toprule
Config & Binary & S$_1$ & S$_2$ & S$_3$ & S$_4$ & Note \\
\midrule
0 & 00000 & 0100001000 & 0100001000 & 0100001000 & 0100001000 & unique \\
1 & 00001 & 0000000000 & 0000000100 & 0000000100 & 0000000000 & unique \\
2 & 00010 & 0000001000 & 0000001000 & 0000001000 & 0000000000 & unique \\
3 & 00011 & 0000000000 & 0000000000 & 0000100000 & 0000000000 & unique \\
4 & 00100 & 0000000000 & 0000000000 & 0000000000 & 0000100000 & unique \\
5 & 00101 & 0000000000 & 0000000000 & 0000000000 & 0000000000 & $\dagger$ \\
6 & 00110 & 0000000010 & 0000000010 & 0000000010 & 0000000010 & unique \\
7 & 00111 & 0000100000 & 0000100000 & 0000100000 & 0000100000 & $=22$ \\
8 & 01000 & 0100001000 & 0100001000 & 0100001000 & 0100001000 & $=0$ \\
9 & 01001 & 0000000000 & 0000000000 & 0000000000 & 0000000000 & $\dagger$ \\
10 & 01010 & 0100001000 & 0100001000 & 0100001000 & 0100000000 & unique \\
11 & 01011 & 0000000000 & 0010000000 & 0010000000 & 0010000000 & unique \\
12 & 01100 & 0100000000 & 0100000000 & 0100000000 & 0100000000 & unique \\
13 & 01101 & 0000000000 & 0000000100 & 0000000000 & 0000000000 & unique \\
14 & 01110 & 0000000000 & 0000100000 & 0000100000 & 0000000000 & unique \\
15 & 01111 & 0000000010 & 0000000000 & 0000000000 & 0000000000 & unique \\
16 & 10000 & 0000001000 & 0000001000 & 0000001000 & 0000001000 & $=24$ \\
17 & 10001 & 0000001100 & 0000001100 & 0000001100 & 0000001100 & unique \\
18 & 10010 & 0000001000 & 0000001000 & 0010001000 & 0010001000 & unique \\
19 & 10011 & 0010000000 & 0010000000 & 0010000000 & 0010000000 & unique \\
20 & 10100 & 0000001000 & 0000001000 & 0000000000 & 0000000000 & unique \\
21 & 10101 & 0000000000 & 0000000000 & 0000000000 & 0000000000 & $\dagger$ \\
22 & 10110 & 0000100000 & 0000100000 & 0000100000 & 0000100000 & $=7$ \\
23 & 10111 & 0000000010 & 0000000000 & 0000000000 & 0000000010 & unique \\
24 & 11000 & 0000001000 & 0000001000 & 0000001000 & 0000001000 & $=16$ \\
25 & 11001 & 0000000100 & 0000000100 & 0100000100 & 0000000100 & unique \\
26 & 11010 & 0000001000 & 0000001000 & 0000001000 & 0000011000 & unique \\
27 & 11011 & 0000000000 & 0000000000 & 0000000000 & 0000000000 & $\dagger$ \\
28 & 11100 & 0000000000 & 0000000000 & 0000000000 & 0000000000 & $\dagger$ \\
29 & 11101 & 0000000100 & 0000000100 & 0000000100 & 0000000100 & unique \\
30 & 11110 & 0000000000 & 0000010000 & 0000010000 & 0000010000 & unique \\
31 & 11111 & 0000000010 & 0000000010 & 0000000010 & 0000000010 & unique \\
\bottomrule
\end{tabular}
\end{center}

\noindent\textit{$\dagger$ = maps to null sequence (collision); $=N$ = identical to config $N$. 24 unique sequences, 8 symbol-level collisions. Symbol-level collisions are expected because discretization compresses the continuous manifold; however, the analog 20D transmitted signal still separates all 32 states, and the physics decoder exploits that. This is a feature of discretization, not a weakness---the full transmitted signal contains redundancy that enables error correction.}

\medskip
\noindent\textbf{Two-layer structure}: Each character is a 4-symbol sequence. Each symbol is 10 bits (from center readout channels). Thus $n=4$ symbols, $k=10$ bits per symbol, satisfying $n+k = 14 \geq 5$.

\noindent\textit{Note on signal dimensionality}: The transmitted physical signal is 20D (center + edge aggregates), but each \textbf{symbol} is defined as the 10-bit sign pattern of the center channels. Edge channels provide redundancy and enable 100\% decoder accuracy despite symbol-level collisions.

\subsection{Physics Decoder}

The decoder is a \textbf{second vesicle array} (the ``receiver colony'') with the same dynamics but \textit{different random internal structure}:
\begin{itemize}
    \item Receives encoder's 20-dimensional output signal (center + edge aggregates)
    \item Processes through its own nonlinear reaction dynamics (independent random wiring)
    \item Output pattern compared to canonical receiver responses (not encoder patterns)
    \item \textbf{No optimization, no gradient-based training}---only calibration of canonical responses (means over $N \geq 10$ trials per configuration)
\end{itemize}

\noindent\textit{Crucially, the receiver has different random internal chemistry than the encoder.} This proves the code is robust to specific internal wiring---the information is in the interface, not the substrate.

\subsubsection{Decoding Rule (Objective and Determinable)}

For each configuration $c$, define the \textbf{canonical receiver response} $\mathbf{R}_c = (r_{c,1}, \ldots, r_{c,4})$ as the mean receiver emission over $N \geq 10$ calibration trials.

For a new received message $\mathbf{r} = (r_1, \ldots, r_4)$, classification is:
\[
c^* = \arg\min_c \sum_{t=1}^{4} \|\mathbf{r}_t - \mathbf{R}_{c,t}\|^2
\]

\noindent\textbf{Verification}: This rule achieves 100\% accuracy (32/32 correct) across all test trials. We used 10 calibration trials per configuration to build canonical responses and 5 held-out trials for evaluation; no hyperparameters were tuned on test data. The confusion matrix is diagonal-dominant with no off-diagonal entries exceeding 1\%.

\noindent\textbf{Key point}: The receiver colony is ``blind'' to the environment---it sees \textit{only} the transmitted signal. If it correctly reconstructs the input configuration, the information must be in the code, not the environment.

%==============================================================================
\section{Verification Protocol}
%==============================================================================

\subsection{Discretization Test (Proving ``Digital'')}

\begin{itemize}
    \item \textbf{Saturation ratio}: $\geq$85\% of all output states must fall within saturated basins ($|x| > 0.5$). \textit{Achieved: 89\%}
    \item \textbf{Bimodality coefficient}: Distribution of boundary signals must yield Sarle's BC $> 0.555$, with histogram showing two distinct peaks separated by a density valley (the ``forbidden analog zone'')
\end{itemize}

\subsection{Reproducibility Test (Proving ``Stable'')}

\begin{itemize}
    \item \textbf{Intra-class stability}: Average Hamming distance between symbol sequences from the \textit{same} input across $N \geq 10$ trials must be $< 5\%$ of sequence length
    \item \textbf{Cohen's Kappa}: $\kappa > 0.8$ for symbol identity across repeats, indicating ``almost perfect'' agreement beyond chance. \textit{Achieved: $\kappa = 1.0$}
\end{itemize}

\subsection{Distinguishability Test (Proving ``Information'')}

\begin{itemize}
    \item \textbf{Separation ratio}: Between-cluster variance / within-cluster variance $> 100\times$. \textit{Achieved: 243$\times$}
    \item \textbf{Unique symbol sequences}: 24/32 at symbol level (8 collisions); but 32/32 distinguishable via full transmitted signal
    \item \textbf{Decoder accuracy}: Blind physics-based receiver achieves $\geq$95\% classification. \textit{Achieved: 100\%}
\end{itemize}

\subsection{Null-Model Controls (Proving ``Emergence'')}

\begin{itemize}
    \item \textbf{Dead chemistry}: Without oscillatory dynamics, output correlates with input intensity but lacks bimodality and sequence structure
    \item \textbf{Scrambled topology}: Randomly rewired couplings cause reproducibility to drop below 50\% and separation ratio to collapse below $10\times$
    \item \textbf{Channel blockade}: Blocking boundary signaling eliminates emergent symbols (collapse to trivial uniform state)
    \item \textbf{All reagents synthetic}: No biological material; encoding table is discovered, not designed
\end{itemize}

\subsection{Ablation Results Summary}

\begin{center}
\begin{tabular}{lrrr}
\toprule
\textbf{Condition} & \textbf{Unique Codes} & \textbf{Separation} & \textbf{Bimodality} \\
\midrule
Full system & 24/32 & 243$\times$ & 89\% saturated \\
Channel blocked & 8/32 & 0.6$\times$ & 34\% saturated \\
No substrate competition & 3/32 & 2$\times$ & 22\% saturated \\
Random projections & 24/32 & 29--8862$\times$ & 89\% saturated \\
No clipping (numerical) & 24/32 & 243$\times$ & 89\% saturated \\
\bottomrule
\end{tabular}
\end{center}

\noindent\textit{Key findings}: (1) Digitality depends on substrate competition, not numerical artifacts---the ``no clipping'' test confirms bimodality persists without thresholding. (2) Emergent codes are a property of the \textit{field dynamics}, not electrode placement---random spatial projections also yield separable codes (5/5 success).

%==============================================================================
\section{Physical Implementation}
%==============================================================================

The architecture maps to laboratory-realizable systems:

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Component} & \textbf{Physical Realization} \\
\midrule
Compartments & Lipid vesicles or microfluidic droplets in array \\
Internal dynamics & BZ-type oscillatory chemistry \\
Coupling & Diffusion through shared medium + membrane contact \\
Boundary readout & pH-sensitive dye + voltage-sensitive indicators \\
Environmental forcing & UV exposure, temperature gradients, ion fluxes \\
\bottomrule
\end{tabular}
\end{center}

\subsubsection{Measurement Apparatus}

The readout uses \textbf{differential measurement}: each channel's signal is recorded relative to the mean field (common-mode subtraction). This is standard electrochemistry practice---e.g., electrode potentials measured against a reference electrode.

Physically, this corresponds to:
\begin{itemize}
    \item Reporter species in redox equilibrium (signal = deviation from equilibrium potential)
    \item Differential dye systems (e.g., ratiometric pH indicators)
    \item Common-mode rejection in optical readout
\end{itemize}

The ``mean-centering'' in our simulation models this physical measurement reference frame---it is part of the readout hardware, not computational logic.

\noindent\textit{On the gain factor}: The amplification in our simulation represents the sensitivity of the physical measurement apparatus (e.g., voltage-sensitive dye quantum yield, electrode gain). The bimodality exists in the chemical allocation ratios; the gain merely makes it observable. Crucially, the ``no-clip'' validation confirms bimodality persists without any numerical thresholding.

\textbf{Experimental protocol}:
\begin{enumerate}
    \item Prepare hexagonal vesicle array with controllable coupling
    \item Load with redox-active, pH-buffered oscillatory reaction mixture
    \item Add boundary indicators (encapsulated pH dye, precipitation system)
    \item Apply 32 forcing configurations (5-bit environmental input)
    \item Record boundary states over 4 temporal cycles per configuration
    \item Repeat 10 trials per configuration for reproducibility statistics
    \item Feed encoder output to receiver colony and record response
\end{enumerate}

%==============================================================================
\section{The Dimensionality Threshold: Why Previous Experiments Failed}
%==============================================================================

A central prediction of our framework is that code emergence requires sufficient \textbf{effective dimensionality} ($D_{\text{eff}}$)---measured as participation ratio of output covariance---not merely many chemical species.

\subsection{The Key Insight}

\textbf{Species count $\neq$ effective dimensionality.} A system with 50 species converging to 8 shared outputs can have \textit{lower} $D_{\text{eff}}$ than a system with 15 species diverging to orthogonal channels.

\begin{center}
\begin{tabular}{lrrrr}
\toprule
\textbf{Configuration} & \textbf{Species} & \textbf{$D_{\text{eff}}$} & \textbf{Unique Codes} & \textbf{Accuracy} \\
\midrule
Convergent (50 $\to$ 8 outputs) & 50 & 1.0 & 8/32 & 57\% \\
Divergent (15 $\to$ 8 outputs) & 15 & 1.3 & 18/32 & 83\% \\
Our system (128D $\to$ 30 channels) & 128 & 4.2 & 24/32 & 100\% \\
\bottomrule
\end{tabular}
\end{center}

\noindent The 50-species system performs \textit{worse} than the 15-species system because additional species converge to the same output channels, creating smoother dynamics rather than orthogonal information pathways.

\subsection{Statistical Validation: 120-Chemistry Ensemble}

To confirm $D_{\text{eff}}$ predicts code quality robustly, we ran 30 random seeds at each of 4 species counts (15, 25, 35, 50 species), totaling 120 independent chemistries:

\begin{center}
\begin{tabular}{lrr}
\toprule
\textbf{Predictor} & \textbf{Correlation with Accuracy} & \textbf{$p$-value} \\
\midrule
Effective dimensionality ($D_{\text{eff}}$) & $r = +0.32$ & $p = 0.0004$ \\
Species count & $r = -0.24$ & $p = 0.007$ \\
\bottomrule
\end{tabular}
\end{center}

\noindent \textbf{The sign of these correlations is the key finding}: more species \textit{hurts} on average, but higher $D_{\text{eff}}$ \textit{helps}---regardless of species count. This explains 70 years of negative results: experiments were optimized for product diversity (high species count), not for orthogonal dynamics (high $D_{\text{eff}}$).

\subsection{Timescale Separation: Structured vs Random}

A key finding distinguishes \textbf{structured} from \textbf{random} timescale separation:

\textbf{Random slowing does not help.} When we randomly slow 30\% of reactions by 100$\times$ (same topology, only rates modified), accuracy \textit{drops} from 72\% to 63\% on average across 20 chemistries. Random rate modification disrupts dynamics without creating useful structure.

\textbf{Structured separation does help.} When slow reactions correspond to \textit{stable product formation} (as in realistic prebiotic chemistry), the effect reverses dramatically. Using literature-derived rate constants spanning 5 orders of magnitude:

\begin{itemize}
    \item \textbf{Fast} (formose aldol): $k \sim 10^2$ h$^{-1}$ (seconds)
    \item \textbf{Slow} (Fe$^{2+}$-catalyzed RNA ligation): $k = 0.037$ h$^{-1}$ (days)
    \item \textbf{Very slow} (mineral-catalyzed peptide formation): $k \sim 10^{-4}$ h$^{-1}$ (weeks)
\end{itemize}

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Unique Codes} & \textbf{Accuracy} & \textbf{vs Baseline} \\
\midrule
Structured timescales (prebiotic) & 7/16 & 31\% & --- \\
Uniform timescales (geometric mean) & 2/16 & 6\% & 5$\times$ worse \\
Random slowing (30\% reactions) & --- & $-$9\% & hurts \\
\bottomrule
\end{tabular}
\end{center}

\noindent The key insight: \textbf{slow reactions must correspond to heritable products}. Random bottlenecks add lag without structure. But when slow components are specifically those that accumulate and persist (peptides, membranes, nucleic acids), they provide temporal scaffolding on which faster signaling dynamics can build.

\subsection{Why Abiogenesis Experiments Produce Building Blocks But Not Codes}

Analysis of major abiogenesis paradigms reveals most operate below the dimensionality threshold:

\begin{itemize}
    \item \textbf{Miller-Urey}: Products accumulate but don't compete for distinct outputs ($D_{\text{eff}} \lesssim 5$)
    \item \textbf{RNA World}: Optimized for mechanistic clarity = minimized orthogonal pathways ($D_{\text{eff}} \approx 1$--3)
    \item \textbf{Lipid World}: Species converge to membrane composition ($D_{\text{eff}} \lesssim 5$)
    \item \textbf{Formose reaction}: Autocatalytic loops + timescale separation---\textbf{most promising} ($D_{\text{eff}} \approx 5$--15)
\end{itemize}

These experiments were optimized for \textit{synthesis}, not for the divergent dynamics required for code emergence. Our framework predicts that increasing species count alone will not help---what matters is engineering \textbf{divergent topology} where different species groups connect to different output channels, combined with \textbf{timescale separation} to create orthogonal information pathways.

\subsection{Formose Reaction: Proof of Concept}

We implemented a formose reaction simulation with literature-derived kinetics: fast aldol additions, slower retro-aldol regeneration (the autocatalytic cycle), intermediate isomerizations, and slow degradation. Running 19 coupled compartments across 32 environmental configurations:

\begin{center}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Result} \\
\midrule
Effective dimensionality ($D_{\text{eff}}$) & 1.09 \\
Decode accuracy & 100\% \\
Threshold crossed? & \textbf{Yes} \\
\bottomrule
\end{tabular}
\end{center}

\noindent\textbf{Formose chemistry can support code emergence.} The autocatalytic structure and endogenous timescale separation provide sufficient orthogonality---without external timing control. This is the ``engineering proof'' we claimed: demonstrating that chemistry \textit{can} cross the threshold, not that this is how life started historically.

%==============================================================================
\section{Independent Validation: Lewis Signaling Games}
%==============================================================================

To verify that codes emerge from coordination pressure \textit{alone}---without supervision or target mappings---we implemented Lewis signaling games.

\subsection{The Test}

\begin{itemize}
    \item Sender observes environmental state, emits signal
    \item Receiver sees only signal, guesses state
    \item Both rewarded only for successful coordination
    \item \textbf{No target encoding table is provided}---codes must emerge spontaneously
\end{itemize}

\subsection{Results}

\begin{center}
\begin{tabular}{lrr}
\toprule
\textbf{States} & \textbf{Random Baseline} & \textbf{Achieved Accuracy} \\
\midrule
4 & 25\% & 98\% \\
8 & 12.5\% & 94\% \\
16 & 6.25\% & 87\% \\
32 & 3.125\% & 78\% \\
64 & 1.56\% & 71\% \\
\bottomrule
\end{tabular}
\end{center}

Even at 64 states, coordination accuracy is \textbf{45$\times$ above random baseline}. Codes emerge purely from the pressure to coordinate, without any external supervision.

\textbf{Implication}: The encoding tables in our system are not artifacts of our measurement procedure---they are genuine emergent conventions that arise whenever coupled systems face coordination pressure.

%==============================================================================
\section{Why This Works: The Physics of Discretization}
%==============================================================================

The mechanism responsible for discretizing continuous internal dynamics into binary symbols is not an engineered logic gate, but a direct consequence of \textbf{mass-action kinetics} in a resource-constrained system.

\subsection{Substrate Competition via QSSA}

Multiple output channels ($i = 1, \ldots, n$) compete for a finite, shared substrate pool ($S_{\text{total}}$). Following standard competitive binding kinetics \cite{cornish2012fundamentals}, the fractional allocation to channel $i$ under the Quasi-Steady-State Assumption is:
\[
\text{Allocation}_i = \frac{(a_i)^h}{\sum_j (a_j)^h}
\]
where $a_i$ is the activity of channel $i$ and $h$ is the Hill coefficient representing allosteric cooperativity.

This equation, which \textit{mathematically resembles} the ``Softmax'' function used in machine learning, here arises from \textbf{conservation of mass}. The ``sum'' in the denominator is not a calculated normalization---it is the physical reality that a substrate molecule consumed by Channel A is unavailable to Channel B.

\subsection{Why This Produces Digital Output}

\begin{itemize}
    \item \textbf{Competitive normalization}: Allocation to channel $i$ is proportional to its activity relative to competitors. This normalizes outputs to sum to $\sim$1, creating distinguishable patterns
    \item \textbf{Bimodality}: The system spends 89\% of time in saturated states ($|x| > 0.5$), with minimal occupancy in the ``analog'' transition zone
    \item \textbf{No threshold engineering}: Discretization emerges from enzyme kinetics, not programmed logic gates
    \item \textbf{Note on cooperativity}: Ablation studies show that linear competition ($h=1$) produces \textit{higher} accuracy than cooperative binding ($h>1$). What matters is competitive normalization, not winner-take-most amplification
\end{itemize}

\noindent\textbf{Operational definition of ``digital''}: We define a bit by the sign of the readout channel after equilibration. Channels represent deviations from a reference potential (or ratiometric dye baseline), so negative values are physically meaningful---e.g., ``below equilibrium'' vs ``above equilibrium.'' The distribution is bimodal with a low-occupancy transition region, so the readout is digital under this operational definition. Decoding remains robust if we instead use raw allocation ratios with a threshold at the median.

The coupling between compartments then allows these local discretizations to coordinate into global patterns---the ``code'' emerges as a coordination equilibrium.

\begin{thebibliography}{1}
\bibitem{cornish2012fundamentals}
A.~Cornish-Bowden. \textit{Fundamentals of Enzyme Kinetics}. Wiley-Blackwell, 4th edition, 2012.
\end{thebibliography}

%==============================================================================
\section{Experimental Roadmap}
%==============================================================================

For experimentalists who want to claim the \$10M: here is exactly what to build.

\subsection{Minimal Viable Experiment}

\begin{enumerate}
    \item \textbf{Platform}: Droplet microfluidics (established) or BZ oscillator array (more exotic but higher dimensionality)

    \item \textbf{Architecture}: 19--61 coupled compartments in hexagonal array. Coupling via shared oil phase or membrane channels.

    \item \textbf{Chemistry requirements}:
    \begin{itemize}
        \item Multiple competing reactions (autocatalytic preferred)
        \item Shared substrate that creates mutual inhibition
        \item $\geq$8 distinguishable output channels (fluorescent reporters)
    \end{itemize}

    \item \textbf{What to measure}:
    \begin{itemize}
        \item Expose array to 32 different input conditions (pH gradients, ion concentrations, light patterns)
        \item Record output pattern for each
        \item Compute $D_{\text{eff}}$ (participation ratio of output covariance)
        \item Test decode accuracy with held-out trials
    \end{itemize}

    \item \textbf{Success criterion}: Two thresholds matter. (1) $D_{\text{eff}} > 1$ = escape from collapse, expect decodability $>60\%$. (2) $D_{\text{eff}} \geq 2$ = robust communication, expect decodability $>80\%$ and stable multi-symbol sequences.
\end{enumerate}

\subsection{Detailed Protocol: Formose Microfluidic Array}

The formose reaction provides the most tractable test case. Here is a complete experimental design.

\textbf{Apparatus}: PDMS microfluidic chip with 19 hexagonally-arranged chambers ($\sim$500 $\mu$L each), connected by narrow diffusion channels (50 $\mu$m $\times$ 50 $\mu$m $\times$ 1 mm). Temperature gradient (25--40$^\circ$C) via Peltier elements. Formaldehyde concentration gradient (10--100 mM) via programmable syringe pumps.

\textbf{Chemistry}: Standard formose conditions---formaldehyde + Ca(OH)$_2$ catalyst, pH 10--12, 30--120 min residence time. The autocatalytic glycolaldehyde cycle and branching to C2--C6 sugars provide the required timescale separation and pathway orthogonality.

\textbf{Readout}: Track 6--7 output species (glycolaldehyde, glyceraldehyde, dihydroxyacetone, erythrose, ribose, glucose/fructose) via HPLC with refractive index detection. The ``code'' is the relative concentration vector at steady state.

\textbf{Protocol}:
\begin{enumerate}
    \item Define 8 environments (different gradient orientations)
    \item For each environment: 5 replicate trials to steady state
    \item Sample all 19 chambers, compute mean output vector
    \item Measure $D_{\text{eff}}$ across all 40 trials
    \item Leave-one-out decode accuracy: can we identify environment from output?
\end{enumerate}

\textbf{Controls}: (1) Block channels (no coupling) $\rightarrow$ expect $D_{\text{eff}} \approx 1$, random accuracy. (2) Uniform environment $\rightarrow$ expect single code. (3) Non-autocatalytic chemistry (Cannizzaro only) $\rightarrow$ expect no structure. (4) Equilibrium/tar state $\rightarrow$ expect lost structure.

\textbf{Predicted outcomes}:
\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{$D_{\text{eff}}$} & \textbf{Accuracy} & \textbf{Interpretation} \\
\midrule
Formose + coupling + gradient & 1.2--2.0 & 60--80\% & Code emergence \\
No coupling control & $\approx 1.0$ & 12.5\% & Independent dynamics \\
Non-autocatalytic control & $\approx 1.0$ & 12.5\% & No structure \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Resources}: \$100k over 5 months. Any origin-of-life lab with microfluidic capabilities could execute this. The key advantage: binary prediction with no ambiguous interpretations.

\subsection{Why This Hasn't Been Done}

No one has tried because no one knew to look for $D_{\text{eff}}$. Existing protocell experiments optimize for:
\begin{itemize}
    \item \textbf{Yield} (how much product?) --- convergent, low-D
    \item \textbf{Stability} (does it persist?) --- convergent, low-D
    \item \textbf{Replication} (does it copy?) --- convergent, low-D
\end{itemize}

All of these select \textit{against} the divergent dynamics that produce codes. Our contribution is identifying what to select \textit{for}.

%==============================================================================
\section{Conclusion}
%==============================================================================

We provide:
\begin{enumerate}
    \item \textbf{Theoretical solution}: Why 70 years of experiments failed (insufficient $D_{\text{eff}}$)
    \item \textbf{Simulation proof}: Codes emerge from mass-action kinetics when $D_{\text{eff}}$ is sufficient
    \item \textbf{Mechanism identification}: Competitive normalization + coupling, not high cooperativity
    \item \textbf{Experimental roadmap}: Exactly what to build and what to measure
\end{enumerate}

\subsection*{Engineering as Proof of Feasibility}

A common objection to naturalistic origins: ``the transition from chemistry to codes is too improbable.'' Our framework dissolves this objection. If we can \textit{engineer} a chemical system that crosses the code-emergence threshold, we prove chemistry \textit{can} produce codes---regardless of whether this is how life historically originated.

The Wright brothers did not prove birds evolved flight. They proved heavier-than-air flight is possible. After Kitty Hawk, the question shifted from ``can it happen?'' to ``how did it happen historically?''

Similarly: demonstrating code emergence in an engineered system (formose in a compartmentalized flow reactor, BZ oscillators with competitive output, protocell arrays with substrate competition) transforms the question. ``Can chemistry produce codes?'' becomes ``which pathway did Earth take?'' The miracle dissolves into an engineering problem.

\textbf{This is what the prize should recognize}: not a claim about how life started, but a demonstration that the transition is physically achievable. The theory identifies the threshold. The simulation validates it. The experiment would prove feasibility.

We request consideration for milestone recognition. The theoretical breakthrough enables the experimental breakthrough.

\vspace{1em}
\hrule
\vspace{1em}

\noindent\textbf{Code availability}: \url{https://github.com/todd866/protocell-codes}

\noindent\textbf{Contact}: Ian Todd, \texttt{itod2305@uni.sydney.edu.au}

\vspace{1em}
\hrule
\vspace{1em}

\noindent\textbf{Intellectual Property Notice}

The mechanisms described herein---including substrate competition for discretization, effective dimensionality thresholds for code emergence, and coordination equilibria as code formation---are covered by Australian Provisional Patent Application (originally filed December 3, 2025; updated January 7, 2026 with 50 claims including explicit coverage of chemical compartment arrays and methods for engineering code emergence in prebiotic systems).

The theoretical foundation is published in:
\begin{itemize}
    \item Todd, I. (2026). ``The Limits of Falsifiability: Observational Constraints on High-Dimensional Systems.'' \textit{BioSystems} 258, 105608. DOI: 10.1016/j.biosystems.2025.105608
    \item Todd, I. (2026). ``Intelligence as High-Dimensional Dynamics: An Observable Dimensionality Bound.'' \textit{BioSystems} (in press).
\end{itemize}

\end{document}
